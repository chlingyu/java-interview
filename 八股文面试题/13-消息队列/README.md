# 13 - 消息队列

> 覆盖消息队列核心知识：以 Kafka 为主，兼顾 RabbitMQ/RocketMQ 共性问题。包括消息可靠性、顺序性、重复消费、高可用等高频面试考点。消息丢失和重复消费几乎每场必问。

---

## 一、基础

### 1. 为什么要用消息队列？

> ⭐⭐⭐⭐⭐ 必考 | 难度：⭐⭐

**一句话回答**：消息队列的三大核心作用——解耦、异步、削峰。

**通俗理解**：

把消息队列想象成一个快递驿站：

- **解耦** = 你寄快递不用亲自送到对方手上，扔到驿站就行。对方什么时候取、怎么取，跟你无关。发件人和收件人互不依赖 → 系统之间不直接调用，通过 MQ 通信
- **异步** = 你把快递扔到驿站后就可以去干别的事了，不用站在对方门口等他开门。主流程快速返回，耗时操作异步处理 → 提升响应速度
- **削峰** = 双 11 快递爆仓，驿站先把包裹堆着，快递员按自己的速度慢慢送。不会因为瞬间涌入大量包裹就把快递员压垮 → 缓冲高并发流量

**回到技术**："驿站"就是消息队列（Kafka、RabbitMQ 等），"寄快递"就是生产者发消息，"取快递"就是消费者消费消息。上游系统只管往 MQ 里写，下游系统按自己的能力消费，两边互不影响。

| 作用 | 没有 MQ | 有了 MQ |
|------|---------|---------|
| **解耦** | A 系统直接调 B、C、D，任何一个挂了都影响 A | A 只管发消息，B/C/D 各自消费，互不影响 |
| **异步** | A 调 B 要等 B 返回，整体耗时 = 所有调用之和 | A 发完消息就返回，⚡**耗时从串行变并行** |
| **削峰** | 瞬时 5000 QPS 直接打到数据库，数据库扛不住 | MQ 缓冲，消费者按 ⚡**稳定速率**消费 |

> **引入 MQ 的代价**：系统复杂度增加（要考虑消息丢失、重复消费、顺序性等问题）、可用性降低（MQ 本身可能挂）、数据一致性问题。所以不要为了用而用，只有系统间确实需要解耦或有削峰需求时才引入。

**🎤 面试这样答**：
> "消息队列的核心作用有三个：一是解耦，上下游系统通过 MQ 通信，互不依赖；二是异步，主流程发完消息就返回，耗时操作异步处理，提升响应速度；三是削峰，高并发流量先堆积在 MQ 中，消费者按自己的能力消费，保护下游系统。但引入 MQ 也会带来复杂度，需要处理消息丢失、重复消费、顺序性等问题。"

---

### 2. Kafka 的架构？核心概念？

> ⭐⭐⭐⭐⭐ 必考 | 难度：⭐⭐⭐

**一句话回答**：Kafka 由 Producer、Broker、Consumer、Zookeeper（新版用 KRaft）组成，数据按 Topic 分类，每个 Topic 分成多个 Partition 实现并行处理。

**通俗理解**：

把 Kafka 想象成一个大型报刊亭：
- **Topic** = 报纸的种类（体育报、财经报、娱乐报）
- **Partition** = 每种报纸有多个投递箱，分散在不同地点，多个邮递员可以同时投递 → ⚡**并行处理**
- **Producer** = 记者，写好稿子投到对应的投递箱
- **Consumer** = 读者，从投递箱取报纸看
- **Consumer Group** = 一个家庭订了报纸，家里谁看都行，但一份报纸只需要一个人看 → 同一个消费组内，一个 Partition 只能被一个 Consumer 消费
- **Broker** = 报刊亭本身，存放所有报纸的地方（Kafka 服务器节点）

**回到技术**："投递箱"就是 Partition，它是 Kafka 并行处理的最小单位。一个 Topic 可以有多个 Partition，分布在不同的 Broker 上。每个 Partition 内部消息是有序的，但不同 Partition 之间不保证顺序。

| 概念 | 说明 |
|------|------|
| **Broker** | Kafka 服务器节点，一个集群有多个 Broker |
| **Topic** | 消息的分类，逻辑概念 |
| **Partition** | Topic 的物理分片，⚡**一个 Topic 可以有多个 Partition** |
| **Replica** | Partition 的副本，分为 Leader 和 Follower，⚡**读写都走 Leader** |
| **Consumer Group** | 消费者组，组内每个 Partition 只被一个 Consumer 消费 |
| **Offset** | 消息在 Partition 中的偏移量，Consumer 通过 offset 记录消费进度 |

```
Kafka 架构示意

Producer ──→ Broker 集群
               ├── Topic-A
               │     ├── Partition-0 (Leader)  ←→ Replica (Follower)
               │     ├── Partition-1 (Leader)  ←→ Replica (Follower)
               │     └── Partition-2 (Leader)  ←→ Replica (Follower)
               └── Topic-B
                     └── ...
                                    ──→ Consumer Group
                                          ├── Consumer-1 ← Partition-0
                                          ├── Consumer-2 ← Partition-1
                                          └── Consumer-3 ← Partition-2
```

> **Consumer 数量和 Partition 的关系**：同一个消费组内，Consumer 数量⚡**不要超过 Partition 数量**，否则多出来的 Consumer 会闲置。最理想的情况是 Consumer 数 = Partition 数，一对一消费。

**🎤 面试这样答**：
> "Kafka 的核心架构由 Producer、Broker、Consumer 组成。消息按 Topic 分类，每个 Topic 分成多个 Partition 分布在不同 Broker 上实现并行和高吞吐。每个 Partition 有多个副本，读写都走 Leader 副本，Follower 异步同步数据保证高可用。消费者以 Consumer Group 为单位消费，组内一个 Partition 只能被一个 Consumer 消费，Consumer 通过 offset 记录消费进度。"

---

## 二、消息可靠性

### 3. 如何保证消息不丢失？

> ⭐⭐⭐⭐⭐ 必考 | 难度：⭐⭐⭐⭐

**一句话回答**：消息可能在生产者、Broker、消费者三个环节丢失，需要分别保障：生产者用回调确认、Broker 用副本+刷盘、消费者用手动提交 offset。

**通俗理解**：

把消息传递想象成寄一封重要信件：
- **生产者丢消息** = 你把信扔进邮筒，但邮筒坏了，信掉地上了 → 没确认信是否投递成功
- **Broker 丢消息** = 邮局收到信了，但还没存进仓库就着火了 → 消息在内存中还没持久化就宕机
- **消费者丢消息** = 收件人签收了，但还没拆开看就把信扔了 → 提交了 offset 但还没处理完消息

**回到技术**："确认投递成功"就是生产者的 ack 回调机制。"存进仓库"就是 Broker 把消息写入磁盘并同步到副本。"签收后再看"就是消费者处理完消息后再手动提交 offset。

| 丢失环节 | 原因 | 解决方案 |
|---------|------|---------|
| **生产者** | 网络异常，消息没到 Broker | ⚡**acks=all** + 失败重试 |
| **Broker** | Leader 宕机，消息未同步到 Follower | ⚡**副本数 ≥ 2** + `min.insync.replicas ≥ 2` |
| **消费者** | 自动提交 offset 后消息还没处理完就崩了 | ⚡**手动提交 offset**，处理完再提交 |

**Kafka 生产者的 acks 参数**：

| acks 值 | 含义 | 可靠性 |
|---------|------|--------|
| **0** | 发了就不管，不等 Broker 确认 | 最低，可能丢 |
| **1** | Leader 写入成功就返回 | 中等，Leader 挂了可能丢 |
| **all（-1）** | ⚡**Leader + 所有 ISR 副本**都写入才返回 | 最高，不丢消息 |

```java
// Kafka 生产者保证不丢消息的配置
Properties props = new Properties();
props.put("acks", "all");              // 所有副本确认
props.put("retries", 3);              // 失败重试 3 次
props.put("enable.idempotence", true); // 开启幂等，防止重试导致重复
```

> **总结口诀**：生产者 acks=all + 重试，Broker 多副本 + 刷盘，消费者手动提交 offset。三管齐下保证消息不丢。

**🎤 面试这样答**：
> "消息可能在三个环节丢失。生产者端，设置 acks=all 确保所有 ISR 副本都写入成功才返回，配合失败重试。Broker 端，设置副本数至少 2 个，min.insync.replicas 至少 2，保证 Leader 挂了数据不丢。消费者端，关闭自动提交 offset，改为处理完消息后手动提交，防止消息还没处理完就标记为已消费。"

---

### 4. 如何保证消息的顺序性？

> ⭐⭐⭐⭐ 高频 | 难度：⭐⭐⭐

**一句话回答**：Kafka 只保证单个 Partition 内消息有序。要保证全局顺序，把需要有序的消息发到同一个 Partition（通过指定相同的 key）。

**通俗理解**：

快递驿站有多个窗口（Partition）同时收件，每个窗口内部是先来先到的，但不同窗口之间没有顺序关系。如果你有三个包裹必须按顺序送达（比如先发合同、再发签字页、最后发盖章件），就必须让它们走同一个窗口。

**回到技术**："走同一个窗口"就是让这些消息发到同一个 Partition。Kafka 生产者发消息时可以指定 key，相同 key 的消息会被哈希到同一个 Partition，从而保证顺序。

| 场景 | 方案 |
|------|------|
| **全局有序** | Topic 只设 ⚡**1 个 Partition**（牺牲并行性能，很少用） |
| **局部有序**（常用） | 相同业务 key 的消息发到⚡**同一个 Partition** |

```java
// 指定 key，相同 orderId 的消息会进入同一个 Partition
producer.send(new ProducerRecord<>("order-topic", orderId, message));
```

> **消费端也要注意**：如果消费者内部用多线程处理消息，也可能打乱顺序。解决办法是按 key 分发到不同的内存队列，每个队列单线程消费。

**🎤 面试这样答**：
> "Kafka 只保证单个 Partition 内消息有序。要保证顺序性，生产者发消息时指定相同的 key，比如用订单 ID 作为 key，这样同一个订单的消息会被哈希到同一个 Partition，保证局部有序。消费端如果用多线程处理，也要按 key 分发到不同队列单线程消费，避免乱序。"

---

### 5. 如何处理重复消费？（幂等性）

> ⭐⭐⭐⭐⭐ 必考 | 难度：⭐⭐⭐

**一句话回答**：消息重复消费是不可避免的（网络抖动、重试、Rebalance 都可能导致），关键是让消费端做到幂等——同一条消息消费多次，结果和消费一次一样。

**通俗理解**：

快递员可能因为系统故障给你送了两次同一个包裹。你不能因为收到两次就付两次钱。正确的做法是：看一眼快递单号，发现已经签收过了，第二次直接拒收。

**回到技术**："看快递单号"就是用一个唯一标识来判断消息是否已经处理过。常见的幂等方案：

| 方案 | 做法 | 适用场景 |
|------|------|---------|
| **唯一 ID + 去重表** | 消息带唯一 ID，消费前查数据库，处理过就跳过 | 通用方案 |
| **数据库唯一约束** | 利用 UNIQUE KEY 防止重复插入 | 插入场景 |
| **Redis SET NX** | 用消息 ID 作为 key，SET NX 成功才处理 | 高性能去重 |
| **乐观锁（版本号）** | `UPDATE ... SET version = version + 1 WHERE version = ?` | 更新场景 |

```java
// 幂等消费示例：用 Redis 去重
public void consume(Message msg) {
    String msgId = msg.getId();
    // SET NX：如果 key 不存在才设置成功，返回 true
    Boolean success = redis.opsForValue()
        .setIfAbsent("consumed:" + msgId, "1", 24, TimeUnit.HOURS);
    if (!success) {
        return; // 已经消费过，直接跳过
    }
    // 执行业务逻辑...
}
```

**🎤 面试这样答**：
> "消息重复消费在分布式环境下是不可避免的，所以关键是保证消费端的幂等性。常见方案有：用消息的唯一 ID 配合数据库去重表或 Redis SET NX 做去重判断；利用数据库唯一约束防止重复插入；更新操作用乐观锁加版本号控制。核心思路就是在消费前判断这条消息是否已经处理过。"

---

## 三、消息积压

### 6. 消息积压了怎么处理？

> ⭐⭐⭐⭐ 高频 | 难度：⭐⭐⭐

**一句话回答**：消息积压说明消费速度跟不上生产速度。短期靠扩容消费者，长期靠排查消费慢的根因。

**通俗理解**：

餐厅后厨出菜太慢，等候区全是人。解决办法：短期多叫几个厨师（扩容），长期看看是哪道菜太费时间（排查瓶颈）。

**回到技术**："多叫厨师"就是增加消费者实例数，但 Kafka 中消费者数量不能超过 Partition 数，超过了多余的消费者会空闲。"哪道菜太费时间"就是排查消费端是否有慢查询、远程调用超时、锁竞争等问题。

| 阶段 | 措施 |
|------|------|
| **紧急处理** | ① 增加消费者实例数（⚡**不能超过 Partition 数**）② 如果 Partition 不够，临时新建 Topic 扩大 Partition 数，用一批消费者把积压消息转发过去 |
| **排查根因** | 消费者是不是有慢查询、远程调用超时、死锁等问题 |
| **预防措施** | 消费端做好监控告警，积压超过阈值及时通知；提前做好容量规划 |

> **注意**：如果消息有过期时间（TTL），积压太久消息可能被丢弃。这种情况需要在业务低峰期写程序把丢失的数据从数据库重新查出来补发到 MQ。

**🎤 面试这样答**：
> "消息积压说明消费速度跟不上生产速度。紧急处理是增加消费者实例数，但不能超过 Partition 数；如果 Partition 不够就临时扩 Partition。同时要排查消费端是否有慢查询或超时等瓶颈。长期要做好监控告警和容量规划。"

---

## 四、Kafka 性能

### 7. Kafka 为什么吞吐量这么高？

> ⭐⭐⭐⭐ 高频 | 难度：⭐⭐⭐

**一句话回答**：Kafka 高吞吐靠四大技术——分区并行、顺序写磁盘、Page Cache、零拷贝。

| 技术 | 原理 | 效果 |
|------|------|------|
| **分区并行** | 一个 Topic 多个 Partition，多个消费者并行消费 | ⚡**水平扩展吞吐量** |
| **顺序写磁盘** | 消息追加写入日志文件，不做随机写 | 顺序写速度接近内存，⚡**比随机写快 1000 倍** |
| **Page Cache** | 利用操作系统的页缓存，写消息先写内存，由 OS 异步刷盘 | 减少用户态到内核态的切换 |
| **零拷贝（Zero Copy）** | 消费者读消息时，数据从磁盘直接通过 `sendfile()` 发到网卡，⚡**不经过用户态** | 减少两次数据拷贝和上下文切换 |

```
传统 IO（4 次拷贝）：
  磁盘 → 内核缓冲区 → 用户缓冲区 → Socket 缓冲区 → 网卡

零拷贝（2 次拷贝）：
  磁盘 → 内核缓冲区 → 网卡（跳过用户态）
```

> **面试追问**：Kafka 的消息存储结构？每个 Partition 对应磁盘上一个目录，里面是分段的日志文件（`.log`），配合索引文件（`.index`）快速定位消息。

**🎤 面试这样答**：
> "Kafka 高吞吐主要靠四点：一是分区并行，多个 Partition 可以被多个消费者同时消费；二是顺序写磁盘，消息只做追加写入，顺序写的速度接近内存；三是利用操作系统的 Page Cache，减少直接磁盘 IO；四是零拷贝技术，消费者读消息时数据从磁盘直接发到网卡，不经过用户态，减少了数据拷贝次数。"

---

## 五、MQ 选型

### 8. RabbitMQ、RocketMQ、Kafka 怎么选？

> ⭐⭐⭐ 常问 | 难度：⭐⭐

**回答**：三者定位不同，简单说——RabbitMQ 功能全、延迟低，适合中小规模；RocketMQ 是阿里出品，事务消息强，适合电商；Kafka 吞吐量最高，适合大数据和日志场景。

| 对比项 | RabbitMQ | RocketMQ | Kafka |
|--------|----------|----------|-------|
| 语言 | Erlang | Java | Scala + Java |
| 单机吞吐 | 万级 | ⚡**十万级** | ⚡**百万级** |
| 消息延迟 | ⚡**微秒级** | 毫秒级 | 毫秒级 |
| 事务消息 | 不支持 | ⚡**支持** | 不支持（0.11+ 有幂等和事务但不常用） |
| 适用场景 | 中小公司、复杂路由 | 电商、金融、事务场景 | 大数据、日志采集、流处理 |

> **怎么选？** 如果公司技术栈是 Java 且有事务消息需求 → RocketMQ。如果是大数据/日志场景、追求高吞吐 → Kafka。中小项目、需要灵活路由 → RabbitMQ。面试中如果没特别说明，默认聊 Kafka 即可。

---

## 面试高频程度排序（3~5 年）

| 优先级 | 题目 |
|--------|------|
| ⭐⭐⭐⭐⭐ | 为什么要用消息队列？ |
| ⭐⭐⭐⭐⭐ | 如何保证消息不丢失？ |
| ⭐⭐⭐⭐⭐ | 如何处理重复消费（幂等性）？ |
| ⭐⭐⭐⭐⭐ | Kafka 的架构和核心概念？ |
| ⭐⭐⭐⭐ | 如何保证消息顺序性？ |
| ⭐⭐⭐⭐ | 消息积压怎么处理？ |
| ⭐⭐⭐⭐ | Kafka 为什么吞吐量高？ |
| ⭐⭐⭐ | RabbitMQ、RocketMQ、Kafka 怎么选？ |
